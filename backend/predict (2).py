import tensorflow as tf
import numpy as np
import os
from tensorflow.keras.utils import load_img, img_to_array
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

# --- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è ---
MODEL_PATH = 'my_breed_model.keras'
LABELS_PATH = 'labels.txt'
IMAGE_TO_TEST = 'D:/Users/Oleg/Desktop/3.jpg'  # –í–∫–∞–∂—ñ—Ç—å —à–ª—è—Ö

IMG_SIZE = 160

# ‚öôÔ∏è –ù–ê–õ–ê–®–¢–£–í–ê–ù–ù–Ø –ë–ê–Ñ–°–ê
MC_SAMPLES = 20  # –°–∫—ñ–ª—å–∫–∏ —Ä–∞–∑—ñ–≤ –ø—Ä–æ–≥–Ω–∞—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è (–±—ñ–ª—å—à–µ = —Ç–æ—á–Ω—ñ—à–µ, –∞–ª–µ –ø–æ–≤—ñ–ª—å–Ω—ñ—à–µ)
ENTROPY_THRESHOLD = 1.5  # –ü–æ—Ä—ñ–≥ "—Ö–∞–æ—Å—É". 0 = –≤–ø–µ–≤–Ω–µ–Ω–∏–π, > 1.5 = –Ω–µ –∑–Ω–∞—é

# 1. –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø
if not os.path.exists(LABELS_PATH):
    print("–ü–æ–º–∏–ª–∫–∞: labels.txt –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
    exit()

with open(LABELS_PATH, "r") as f:
    class_names = [line.strip() for line in f.readlines()]

print(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ...")
model = tf.keras.models.load_model(MODEL_PATH)


# 2. –ü–Ü–î–ì–û–¢–û–í–ö–ê
def preprocess_image(image_path):
    try:
        img = load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))
        img_array = img_to_array(img)
        img_batch = np.expand_dims(img_array, axis=0)
        processed_img = preprocess_input(img_batch)
        return processed_img
    except Exception as e:
        print(f"–ü–æ–º–∏–ª–∫–∞: {e}")
        return None


# 3. –ë–ê–Ñ–°–Ü–í–°–¨–ö–ò–ô –ü–†–û–ì–ù–û–ó (MC DROPOUT)
processed_image = preprocess_image(IMAGE_TO_TEST)

if processed_image is not None:
    print(f"üî¨ –ó–∞–ø—É—Å–∫–∞—é –ë–∞—î—Å—ñ–≤—Å—å–∫–∏–π –∞–Ω–∞–ª—ñ–∑ ({MC_SAMPLES} —ñ—Ç–µ—Ä–∞—Ü—ñ–π)...")

    # –°—Ç–≤–æ—Ä—é—î–º–æ —Å–ø–∏—Å–æ–∫ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤—Å—ñ—Ö –ø—Ä–æ–≥–Ω–æ–∑—ñ–≤
    predictions_list = []

    # –ü—Ä–æ–≥–∞–Ω—è—î–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è N —Ä–∞–∑—ñ–≤
    for i in range(MC_SAMPLES):
        # ‚ùóÔ∏è training=True –∑–º—É—à—É—î Dropout –ø—Ä–∞—Ü—é–≤–∞—Ç–∏ –ø—ñ–¥ —á–∞—Å –ø—Ä–æ–≥–Ω–æ–∑—É
        # –¶–µ —Å—Ç–≤–æ—Ä—é—î –µ—Ñ–µ–∫—Ç "–∞–Ω—Å–∞–º–±–ª—é" –º–æ–¥–µ–ª–µ–π
        pred = model(processed_image, training=True)
        predictions_list.append(pred)

    # –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ –≤ –æ–¥–∏–Ω –≤–µ–ª–∏–∫–∏–π —Ç–µ–Ω–∑–æ—Ä (20, 37)
    predictions_stack = tf.stack(predictions_list)

    # --- –ú–ê–¢–ï–ú–ê–¢–ò–ö–ê ---

    # 1. –°–µ—Ä–µ–¥–Ω—ñ–π –ø—Ä–æ–≥–Ω–æ–∑ (Mean) - —Ü–µ –Ω–∞–π—Ç–æ—á–Ω—ñ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    mean_prediction = tf.reduce_mean(predictions_stack, axis=0)  # shape (1, 37)
    probabilities = tf.nn.softmax(mean_prediction).numpy()[0]

    # 2. –û–±—á–∏—Å–ª–µ–Ω–Ω—è –ï–Ω—Ç—Ä–æ–ø—ñ—ó (–ú—ñ—Ä–∞ –Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω–æ—Å—Ç—ñ)
    # –§–æ—Ä–º—É–ª–∞ –®–µ–Ω–Ω–æ–Ω–∞: -sum(p * log(p))
    # –ù–∏–∑—å–∫–∞ –µ–Ω—Ç—Ä–æ–ø—ñ—è (–±–ª–∏–∑—å–∫–æ 0) = –ú–æ–¥–µ–ª—å –≤–ø–µ–≤–Ω–µ–Ω–∞
    # –í–∏—Å–æ–∫–∞ –µ–Ω—Ç—Ä–æ–ø—ñ—è (> 1) = –ú–æ–¥–µ–ª—å –ø–ª—É—Ç–∞—î—Ç—å—Å—è (—Ä—ñ–≤–Ω–æ–º—ñ—Ä–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª)
    entropy = -np.sum(probabilities * np.log(probabilities + 1e-9))

    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –ø–µ—Ä–µ–º–æ–∂—Ü—è
    predicted_index = np.argmax(probabilities)
    predicted_breed = class_names[predicted_index]
    confidence_percent = probabilities[predicted_index] * 100

    print("\n--- üìä –†–ï–ó–£–õ–¨–¢–ê–¢–ò –ê–ù–ê–õ–Ü–ó–£ ---")
    print(f"–ï–Ω—Ç—Ä–æ–ø—ñ—è (–†—ñ–≤–µ–Ω—å —Å—É–º–Ω—ñ–≤—É): {entropy:.4f}")
    print(f"–ü–æ—Ä—ñ–≥ –≤—ñ–¥—Å—ñ—é–≤–∞–Ω–Ω—è: {ENTROPY_THRESHOLD}")

    print("-" * 30)

    # –õ–æ–≥—ñ–∫–∞ –ø—Ä–∏–π–Ω—è—Ç—Ç—è —Ä—ñ—à–µ–Ω–Ω—è
    if entropy > ENTROPY_THRESHOLD:
        print("‚ùå –ù–ï–í–Ü–î–û–ú–ò–ô –û–ë'–Ñ–ö–¢")
        print("–ú–æ–¥–µ–ª—å –∑–∞–Ω–∞–¥—Ç–æ —Å—É–º–Ω—ñ–≤–∞—î—Ç—å—Å—è (–≤–∏—Å–æ–∫–∞ –µ–Ω—Ç—Ä–æ–ø—ñ—è).")
        print(f"–í–æ–Ω–∞ –¥—É–º–∞—î, —â–æ —Ü–µ –º–æ–∂–µ –±—É—Ç–∏ '{predicted_breed}', –∞–ª–µ –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å —Ä–æ–∑–º–∏—Ç–∞.")
    else:
        breed_clean = predicted_breed.replace('_', ' ').title()
        print(f"‚úÖ –¶–µ: {breed_clean}")
        print(f"–í–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å: {confidence_percent:.2f}%")

    # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–æ–∑–ø–æ–¥—ñ–ª—É (—Ç–µ–∫—Å—Ç–æ–≤–∞)
    print("\n--- –¢–æ–ø-3 –≥—ñ–ø–æ—Ç–µ–∑–∏ –º–æ–¥–µ–ª—ñ ---")
    top_3_indices = np.argsort(probabilities)[-3:][::-1]
    for i in top_3_indices:
        name = class_names[i]
        prob = probabilities[i] * 100
        # –ú–∞–ª—é—î–º–æ –ø—Ä–æ—Å—Ç–∏–π –≥—Ä–∞—Ñ—ñ–∫
        bar = "‚ñà" * int(prob / 5)
        print(f"{name:20} | {prob:5.1f}% {bar}")